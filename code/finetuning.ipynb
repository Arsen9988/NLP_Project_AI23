{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    import pandas as pd\n",
    "    from datasets import Dataset\n",
    "    from transformers import DistilBertTokenizer\n",
    "\n",
    "    X_train = pd.read_csv(\"../data/Train_Test_splits/X_train_50proc_trunc_pad.csv\")\n",
    "    X_test = pd.read_csv(\"../data/Train_Test_splits/X_test_50proc_trunc_pad.csv\")\n",
    "    y_train = pd.read_csv(\"../data/Train_Test_splits/y_train_50proc.csv\")\n",
    "    y_test = pd.read_csv(\"../data/Train_Test_splits/y_test_50proc.csv\")\n",
    "\n",
    "    print(X_train.columns)\n",
    "    print(X_test.columns)\n",
    "    print(y_train.columns)\n",
    "    print(y_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from datasets import load_dataset\n",
    "    from transformers import TFAutoModelForSequenceClassification, DistilBertTokenizer\n",
    "    import tensorflow as tf\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "\n",
    "    if not tf.config.list_physical_devices(\"GPU\"):\n",
    "        print(\"Warning: No GPU found. Performance may be slower.\")\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "        \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    )\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    )\n",
    "\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    test_dataset = dataset[\"test\"].select(range(100))\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512\n",
    "        )\n",
    "\n",
    "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    test_tf_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            np.array(test_dataset[\"input_ids\"]),\n",
    "            np.array(test_dataset[\"attention_mask\"]),\n",
    "            np.array(test_dataset[\"label\"]),\n",
    "        )\n",
    "    ).batch(8)\n",
    "\n",
    "    @tf.function\n",
    "    def predict_step(input_ids, attention_mask):\n",
    "        inputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "        logits = model(inputs, training=False).logits\n",
    "        return np.argmax(logits.numpy(), axis=1)\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    for input_ids, attention_mask, batch_labels in test_tf_dataset:\n",
    "        preds = predict_step(input_ids, attention_mask)\n",
    "        predictions.extend(preds)\n",
    "        labels.extend(batch_labels.numpy())\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import tensorflow as tf\n",
    "    print(tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    from datasets import load_dataset\n",
    "    from transformers import AutoModelForSequenceClassification, DistilBertTokenizer\n",
    "    import torch\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "        \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    ).to(device)\n",
    "\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    test_dataset = dataset[\"test\"].select(range(100))\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512\n",
    "        )\n",
    "\n",
    "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    inputs = torch.tensor(test_dataset[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(test_dataset[\"attention_mask\"]).to(device)\n",
    "    labels = torch.tensor(test_dataset[\"label\"]).to(device)\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(inputs), 8):\n",
    "            batch_input_ids = inputs[i : i + 8]\n",
    "            batch_attention_mask = attention_mask[i : i + 8]\n",
    "            batch_labels = labels[i : i + 8]\n",
    "            outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    import tensorflow as tf\n",
    "\n",
    "    print(tf.config.list_physical_devices(\"GPU\"))\n",
    "    devices = tf.config.list_physical_devices()\n",
    "    print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    import tensorflow as tf\n",
    "\n",
    "    device = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "    device_string = \"GPU is available!\" if device else \"GPU is NOT available.\"\n",
    "    print()\n",
    "    print(device_string)\n",
    "    print()\n",
    "\n",
    "    # Somehow this takes unbelievably long time...\n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        a = tf.random.normal([10, 10])\n",
    "        b = tf.random.normal([10, 10])\n",
    "        c = tf.matmul(a, b)\n",
    "\n",
    "        print(\"Matrix multiplication done on GPU!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test_DL-u3DERucF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
