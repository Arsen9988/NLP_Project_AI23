{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buntish/.local/share/virtualenvs/Test_DL-u3DERucF/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['reviews_decoded'], dtype='object')\n",
      "Index(['reviews_decoded'], dtype='object')\n",
      "Index(['sentiment'], dtype='object')\n",
      "Index(['sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    import pandas as pd\n",
    "    from datasets import Dataset\n",
    "    from transformers import DistilBertTokenizer\n",
    "\n",
    "    X_train = pd.read_csv(\"../data/Train_Test_splits/X_train_50proc_trunc_pad.csv\")\n",
    "    X_test = pd.read_csv(\"../data/Train_Test_splits/X_test_50proc_trunc_pad.csv\")\n",
    "    y_train = pd.read_csv(\"../data/Train_Test_splits/y_train_50proc.csv\")\n",
    "    y_test = pd.read_csv(\"../data/Train_Test_splits/y_test_50proc.csv\")\n",
    "\n",
    "    print(X_train.columns)\n",
    "    print(X_test.columns)\n",
    "    print(y_train.columns)\n",
    "    print(y_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from datasets import load_dataset\n",
    "    from transformers import TFAutoModelForSequenceClassification, DistilBertTokenizer\n",
    "    import tensorflow as tf\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "\n",
    "    if not tf.config.list_physical_devices(\"GPU\"):\n",
    "        print(\"Warning: No GPU found. Performance may be slower.\")\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "        \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    )\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    )\n",
    "\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    test_dataset = dataset[\"test\"].select(range(100))\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512\n",
    "        )\n",
    "\n",
    "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    test_tf_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            np.array(test_dataset[\"input_ids\"]),\n",
    "            np.array(test_dataset[\"attention_mask\"]),\n",
    "            np.array(test_dataset[\"label\"]),\n",
    "        )\n",
    "    ).batch(8)\n",
    "\n",
    "    @tf.function\n",
    "    def predict_step(input_ids, attention_mask):\n",
    "        inputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "        logits = model(inputs, training=False).logits\n",
    "        return np.argmax(logits.numpy(), axis=1)\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    for input_ids, attention_mask, batch_labels in test_tf_dataset:\n",
    "        preds = predict_step(input_ids, attention_mask)\n",
    "        predictions.extend(preds)\n",
    "        labels.extend(batch_labels.numpy())\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 09:51:09.783069: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736844669.804696    9993 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736844669.810778    9993 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-14 09:51:09.833534: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1736844672.103257    9993 gpu_device.cc:2433] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 5.2. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    import tensorflow as tf\n",
    "    print(tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from datasets import load_dataset\n",
    "    from transformers import AutoModelForSequenceClassification, DistilBertTokenizer\n",
    "    import torch\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "        \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    ).to(device)\n",
    "\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    test_dataset = dataset[\"test\"].select(range(100))\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512\n",
    "        )\n",
    "\n",
    "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    inputs = torch.tensor(test_dataset[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(test_dataset[\"attention_mask\"]).to(device)\n",
    "    labels = torch.tensor(test_dataset[\"label\"]).to(device)\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(inputs), 8):\n",
    "            batch_input_ids = inputs[i : i + 8]\n",
    "            batch_attention_mask = attention_mask[i : i + 8]\n",
    "            batch_labels = labels[i : i + 8]\n",
    "            outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    import tensorflow as tf\n",
    "\n",
    "    print(tf.config.list_physical_devices(\"GPU\"))\n",
    "    devices = tf.config.list_physical_devices()\n",
    "    print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is available!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1736844684.224917    9993 gpu_device.cc:2433] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 5.2. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1736844684.225387    9993 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 491 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960, pci bus id: 0000:01:00.0, compute capability: 5.2\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "F0000 00:00:1736844684.262729    9993 random_op_gpu.h:247] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), key, counter, gen, data, size, dist)\n",
      "Status: INTERNAL: no kernel image is available for execution on the device\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    import tensorflow as tf\n",
    "\n",
    "    device = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "    device_string = \"GPU is available!\" if device else \"GPU is NOT available.\"\n",
    "    print()\n",
    "    print(device_string)\n",
    "    print()\n",
    "\n",
    "    # Somehow this takes unbelievably long time...\n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        a = tf.random.normal([10, 10])\n",
    "        b = tf.random.normal([10, 10])\n",
    "        c = tf.matmul(a, b)\n",
    "\n",
    "    print(\"Matrix multiplication done on GPU!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test_DL-u3DERucF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
