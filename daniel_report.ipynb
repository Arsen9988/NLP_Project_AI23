{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projektrapport AI-23 Deep Learning\n",
    "## Finetuning av existerande LLM och modelljämförelse av sentiment analys\n",
    "### Namn:\n",
    "### Projektbeskrivning:\n",
    "- Identifiera en existerande Large Language Modell (LLM), avsedd för sentiment analys, och finetunea den för IMDB reviews.\n",
    "- Binära klasser, dvs \"positvt\" eller \"negativt\". (Vi diskuterade också att utöka det med \"multi class\" men vi hann inte göra det.)\n",
    "- Jämföra olika modellers prestanda map accuracy.\n",
    "### Genomförande:\n",
    "- Vi använde Huggingface för att hitta användbara modeller. Det finns oerhört många olika modeller att välja mellan.\n",
    "- Vi valde att jobba med dessa transformer modeller från Huggingface:\n",
    "1. ***sarahai/movie-sentiment-analysis*** (modell specifikt avsedd för sentimentanalys av IMDB dataset)\n",
    "2. ***distilbert-base-uncased-finetuned-sst-2-english*** (\"distilbert\") Den här modellen är en checkpoint på DistilBERT-base-uncased, finetunead på SST-2 (Stanford Sentiment Treebank). DistilBERT är en engelsk språklig modell förtränad på samma data som BERT (Toronto Book Corpus och hela engelska Wikipedia) med hjälp av distillation under övervakning av bert-base-uncased. Modellen har 6 lager, 768 dimensioner, 12 huvuden och totalt 66 miljoner parametrar. \n",
    "3. ***michelecafagna26/gpt2-medium-finetuned-sst2-sentiment*** (generell modell för sentimentanalys)\n",
    "- Vi valde att även använda OpenAI API, dels för direkt sentimentanalys, men även för att summera texter som var för långa för att fungera med transformer modellerna utan truncation.\n",
    "- GPT-3.5 (för direkt sentimentanalys och summering)\n",
    "- GPT-4o mini (för direkt sentimentanalys)\n",
    "- GPT-4 (för direkt sentimentanalys, men endast begränsat)\n",
    "#### Finetuning:\n",
    "- Vi valde att finetunea distilbert"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
